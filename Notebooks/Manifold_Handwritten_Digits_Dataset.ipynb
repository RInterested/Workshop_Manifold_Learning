{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manifold Learning - Handwritten Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example code is using the following template\n",
    "http://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html\n",
    "\n",
    "## Authors:\n",
    "Fabian Pedregosa <fabian.pedregosa@inria.fr>\n",
    "\n",
    "Olivier Grisel <olivier.grisel@ensta.org>\n",
    "\n",
    "Mathieu Blondel <mathieu@mblondel.org>\n",
    "\n",
    "Gael Varoquaux\n",
    "## License: BSD 3 clause (C) INRIA 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjustments by S.Kuehn, stefan.kuehn@posteo.de\n",
    "\n",
    "print(__doc__)\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import offsetbox\n",
    "%matplotlib inline\n",
    "from sklearn import (manifold, datasets, decomposition, ensemble,\n",
    "                     discriminant_analysis, random_projection)\n",
    "\n",
    "digits = datasets.load_digits(n_class=6)\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "n_samples, n_features = X.shape\n",
    "n_neighbors = 30\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Scale and visualize the embedding vectors\n",
    "def plot_embedding(X, title=None,subplot=111):\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    ax = plt.subplot(subplot)\n",
    "    for i in range(X.shape[0]):\n",
    "        plt.text(X[i, 0], X[i, 1], str(digits.target[i]),\n",
    "                 color=plt.cm.Set1(y[i] / 10.),\n",
    "                 fontdict={'weight': 'bold', 'size': 9})\n",
    "\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Plot images of the digits\n",
    "n_img_per_row = 10\n",
    "img = np.zeros((10 * n_img_per_row, 10 * n_img_per_row))\n",
    "for i in range(n_img_per_row):\n",
    "    ix = 10 * i + 1\n",
    "    for j in range(n_img_per_row):\n",
    "        iy = 10 * j + 1\n",
    "        img[ix:ix + 8, iy:iy + 8] = X[i * n_img_per_row + j].reshape((8, 8))\n",
    "\n",
    "plt.imshow(img, cmap=plt.cm.binary)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('A selection from the 64-dimensional digits dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------\n",
    "# Sparse Random 2D projection using a random unitary matrix\n",
    "print(\"Computing sparse random projection\")\n",
    "srp = random_projection.SparseRandomProjection(n_components=3, random_state=42)\n",
    "X_projected = srp.fit_transform(X)\n",
    "plot_embedding(X_projected, \"Sparse Random Projection of the digits\")\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Gaussian Random 2D projection using a random unitary matrix\n",
    "print(\"Computing Gaussian random projection\")\n",
    "grp = random_projection.GaussianRandomProjection(n_components=3, random_state=42)\n",
    "X_projected = grp.fit_transform(X)\n",
    "plot_embedding(X_projected, \"Gaussian Random Projection of the digits\")\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Projection on to the first 2 principal components\n",
    "\n",
    "print(\"Computing PCA projection\")\n",
    "t0 = time()\n",
    "X_pca = decomposition.TruncatedSVD(n_components=2).fit_transform(X)\n",
    "plot_embedding(X_pca,\n",
    "               \"Principal Components projection of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Isomap projection of the digits dataset\n",
    "print(\"Computing Isomap embedding\")\n",
    "t0 = time()\n",
    "X_iso = manifold.Isomap(n_neighbors, n_components=2).fit_transform(X)\n",
    "print(\"Done.\")\n",
    "plot_embedding(X_iso,\n",
    "               \"Isomap projection of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Locally linear embedding of the digits dataset\n",
    "print(\"Computing LLE embedding\")\n",
    "clf = manifold.LocallyLinearEmbedding(n_neighbors, n_components=2, eigen_solver='dense',\n",
    "                                      method='standard')\n",
    "t0 = time()\n",
    "X_lle = clf.fit_transform(X)\n",
    "print(\"Done. Reconstruction error: %g\" % clf.reconstruction_error_)\n",
    "plot_embedding(X_lle,\n",
    "               \"Locally Linear Embedding of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Modified Locally linear embedding of the digits dataset\n",
    "print(\"Computing modified LLE embedding\")\n",
    "clf = manifold.LocallyLinearEmbedding(n_neighbors, n_components=2, eigen_solver='dense',\n",
    "                                      method='modified')\n",
    "t0 = time()\n",
    "X_mlle = clf.fit_transform(X)\n",
    "print(\"Done. Reconstruction error: %g\" % clf.reconstruction_error_)\n",
    "plot_embedding(X_mlle,\n",
    "               \"Modified Locally Linear Embedding of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# HLLE embedding of the digits dataset\n",
    "print(\"Computing Hessian LLE embedding\")\n",
    "clf = manifold.LocallyLinearEmbedding(n_neighbors, n_components=2, eigen_solver='dense',\n",
    "                                      method='hessian')\n",
    "t0 = time()\n",
    "X_hlle = clf.fit_transform(X)\n",
    "print(\"Done. Reconstruction error: %g\" % clf.reconstruction_error_)\n",
    "plot_embedding(X_hlle,\n",
    "               \"Hessian Locally Linear Embedding of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# LTSA embedding of the digits dataset\n",
    "print(\"Computing LTSA embedding\")\n",
    "clf = manifold.LocallyLinearEmbedding(n_neighbors, n_components=2, eigen_solver='dense',\n",
    "                                      method='ltsa')\n",
    "t0 = time()\n",
    "X_ltsa = clf.fit_transform(X)\n",
    "print(\"Done. Reconstruction error: %g\" % clf.reconstruction_error_)\n",
    "plot_embedding(X_ltsa,\n",
    "               \"Local Tangent Space Alignment of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# MDS  embedding of the digits dataset\n",
    "print(\"Computing MDS embedding\")\n",
    "mds = manifold.MDS(n_components=2, n_init=1, max_iter=100)\n",
    "t0 = time()\n",
    "X_mds = mds.fit_transform(X)\n",
    "print(\"Done. Stress: %f\" % mds.stress_)\n",
    "plot_embedding(X_mds,\n",
    "               \"MDS embedding of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Spectral embedding of the digits dataset\n",
    "print(\"Computing Spectral embedding\")\n",
    "embedder = manifold.SpectralEmbedding(n_components=2, random_state=0, eigen_solver=\"arpack\")\n",
    "\n",
    "t0 = time()\n",
    "X_se = embedder.fit_transform(X)\n",
    "\n",
    "plot_embedding(X_se,\n",
    "               \"Spectral embedding of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# t-SNE embedding of the digits dataset\n",
    "print(\"Computing t-SNE embedding\")\n",
    "tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "t0 = time()\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "plot_embedding(X_tsne,\n",
    "               \"t-SNE embedding of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# UMAP embedding of the digits dataset\n",
    "print(\"Computing UMAP embedding\")\n",
    "import umap\n",
    "X_umap = umap.UMAP(n_neighbors=n_neighbors,\n",
    "                      min_dist=0.3,\n",
    "                      metric='correlation').fit_transform(digits.data)\n",
    "\n",
    "plot_embedding(X_umap,\n",
    "               \"UMAP embedding of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "# Show plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check singular values as criterion for dimensionality of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "t0 = time()\n",
    "svd = TruncatedSVD(n_components=63, n_iter=7, random_state=42)\n",
    "svd.fit(X)  \n",
    "print(np.cumsum(svd.explained_variance_ratio_))  \n",
    "#print(svd.explained_variance_ratio_.sum())  \n",
    "print(svd.singular_values_)\n",
    "t1 = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(range(0,63),svd.singular_values_[0:63])\n",
    "plt.scatter(range(0,63),100*np.cumsum(svd.explained_variance_ratio_),color=plt.cm.Set1(0.8*np.cumsum(svd.explained_variance_ratio_)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first 40 singular values cover 99% of the variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Task Dimensionality Reduction\n",
    "\n",
    "* Use one of the fast manifold learning methods as preprocessor for dimensionality reduction\n",
    "\n",
    "* Then apply some other methods and compare the results and runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------\n",
    "# First: Use Random 2D projection using a random unitary matrix to project to lower dimension (check decay of singular values)\n",
    "# Second: Apply whatever you want\n",
    "print(\"Computing random projection as preprocessing + other methods\")\n",
    "#rp_pre = random_projection.SparseRandomProjection(n_components=16, random_state=0)\n",
    "rp_pre = random_projection.GaussianRandomProjection(n_components=40, random_state=0)\n",
    "t0 = time()\n",
    "X_projected_pre = rp_pre.fit_transform(X)\n",
    "print(X_projected_pre.shape)\n",
    "print(\"Preprocessing time:\", time()-t0) # O\n",
    "#t0 = time()\n",
    "#X_projected_mds = mds.fit_transform(X_projected_pre)\n",
    "#print(\"MDS reduced:\", time()-t0)\n",
    "\n",
    "tsne2 = manifold.TSNE(n_components=2, init='random', random_state=0)\n",
    "#tsne2 = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "t0 = time()\n",
    "X_projected_tsne = tsne2.fit_transform(X_projected_pre)\n",
    "print(\"t-SNE reduced:\",time()-t0)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Plot examples\n",
    "#plot_embedding(X_mds, \"MDS of the digits\")\n",
    "#plot_embedding(X_projected_mds, \"Random Projecton + MDS of the digits\")\n",
    "plot_embedding(X_tsne,\"t-SNE embedding of the digits\")\n",
    "#plot_embedding(X_projected_tsne,\"Random Projection + t-SNE embedding of the digits\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate subplots in given plot\n",
    "# Scale and visualize the embedding vectors\n",
    "def plot_embedding_variant(X, title=None,subplot=111):\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "\n",
    "    ax = plt.subplot(subplot)\n",
    "    for i in range(X.shape[0]):\n",
    "        plt.text(X[i, 0], X[i, 1], str(digits.target[i]),\n",
    "                 color=plt.cm.Set1(y[i] / 10.),\n",
    "                 fontdict={'weight': 'bold', 'size': 9})\n",
    "\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    if title is not None:\n",
    "        plt.title(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First: Use PCA to project to low-dim space (according to decay of singular values)\n",
    "# Second: Apply whatever you want\n",
    "print(\"Computing PCA projection as preprocessing + other methods\")\n",
    "pca_pre = decomposition.TruncatedSVD(n_components=40)\n",
    "t0 = time()\n",
    "X_projected_pre = pca_pre.fit_transform(X)\n",
    "t1 = time()\n",
    "print(\"Preprocessing Time:\", t1-t0)\n",
    "print(\"Reduced Dimension:\", X_projected_pre.shape)\n",
    "\n",
    "#t0 = time()\n",
    "#X_projected_lda = discriminant_analysis.LinearDiscriminantAnalysis(n_components=2).fit_transform(X_projected_pre, y)\n",
    "#t1 = time()\n",
    "\n",
    "#mds = manifold.MDS(n_components=2, n_init=1, max_iter=1000) # change max_iter if you like\n",
    "#t0 = time()\n",
    "#X_mds = mds.fit_transform(X)\n",
    "#t1 = time()\n",
    "\n",
    "#t0 = time()\n",
    "#X_projected_mds = mds.fit_transform(X_projected_pre)\n",
    "#t1 = time()\n",
    "\n",
    "#t0 = time()\n",
    "#X_projected_pca = decomposition.TruncatedSVD(n_components=2).fit_transform(X_projected_pre)\n",
    "#t1 = time()\n",
    "\n",
    "tsne2 = manifold.TSNE(n_components=2, init='random', random_state=0)\n",
    "t0 = time()\n",
    "X_projected_tsne = tsne2.fit_transform(X_projected_pre)\n",
    "t1 = time()\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Plot everything\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "#plot_embedding_variant(X_mds, \"MDS of the digits\",subplot=121)\n",
    "#plot_embedding_variant(X_projected_mds, \"PCA + MDS of the digits\",subplot=122)\n",
    "plot_embedding_variant(X_tsne, \"tSNE of the digits\",subplot=121)\n",
    "plot_embedding_variant(X_projected_tsne, \"PCA + tSNE of the digits: %.2g sec\" % (t1 - t0),subplot=122)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 8))\n",
    "plot_embedding_variant(X_mds, \"MDS of the digits\",subplot=121)\n",
    "plot_embedding_variant(X_projected_mds, \"PCA + MDS of the digits\",subplot=122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
